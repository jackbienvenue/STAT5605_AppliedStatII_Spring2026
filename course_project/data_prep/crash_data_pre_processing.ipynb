{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "839a9070",
   "metadata": {},
   "source": [
    "# Crash Data Big Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420616eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package Upload\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Data Upload\n",
    "\n",
    "## Three files:\n",
    "df_01 = pd.read_csv(\"./data/CT_crashesexport_5673_0.csv\")\n",
    "df_02 = pd.read_csv(\"./data/CT_crashes/export_5673_1.csv\")\n",
    "df_03 = pd.read_csv(\"./data/CT_crashes/export_5673_2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef132519",
   "metadata": {},
   "source": [
    "## Individual File Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f65235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep Columns Lists:\n",
    "\n",
    "## dataset 0:\n",
    "\n",
    "keep_columns_0 = [\n",
    "        \"CrashId\",\n",
    "        \"Fatal Case Status\",\n",
    "        \"Latitude\",\n",
    "        \"Longitude\",\n",
    "        \"Date of Crash\",\n",
    "        \"Day of the Week Text Format\",\n",
    "        \"Hour of the Day\",\n",
    "        \"Most Severe Injury\",\n",
    "        \"Number Of Motor Vehicles\",\n",
    "        \"Number Of Non-Motorist\",\n",
    "        \"Route Class\", \"Route Class Text Format\",\n",
    "        \"First Harmful Event\",\n",
    "        \"Manner of Crash / Collision Impact\",\n",
    "        \"Location of First Harmful Event\",\n",
    "        \"Weather Condition\", \"Weather Condition Text Format\",\n",
    "        \"Light Condition\", \"Light Condition Text Format\",\n",
    "        \"Road Surface Condition\", \"Road Surface Condition Text Format\",\n",
    "        \"Crash Specific Location\", \"Crash Specific Location Text Format\",\n",
    "        \"Type of Intersection\", \"Type of Intersection Text Format\"\n",
    "    ]\n",
    "\n",
    "## dataset 1:\n",
    "\n",
    "keep_columns_1 = [\n",
    "        \"CrashId\", \"VehicleId\", \"Vehicle Unit Type\", \"Make\", \n",
    "        \"Vehicle Model Year\", \"Model\", \"Vehicle Color\", \n",
    "        \"Most Harmful Event\", \"Most Harmful Event Text Format\",\n",
    "        \"Vehicle Manuever/Action\", \"Vehicle Manuever/Action Text Format\",\n",
    "        \"Roadway Grade\", \"Extent of Damage\", \"Extent of Damage Text Format\",\n",
    "        \"Body Type\", \"Body Type Text Format\"\n",
    "    ]\n",
    "\n",
    "## dataset 2:\n",
    "\n",
    "keep_columns_2 = [\n",
    "        \"CrashId\", \"Age\", \"Gender\", \"State\", \"Postal Code\",\n",
    "        \"Person Type\", \"Person Type Text Format\", \"Injury Status\",\n",
    "        \"Air Bag Status\", \"Air Bag Status Text Format\",\n",
    "        \"Speeding Related\", \"Speeding Related Text Format\"\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d304d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precursor functions for Data Cleaning:\n",
    "\n",
    "## IDENTIFY NUMERIC, TEXT FIELDS TO EXPORT TEXT VERSION TO DECODING FILE FOR STORAGE PRESERVATION\n",
    "def extract_decodings(df, decoding_records):\n",
    "    \"\"\"\n",
    "    Extract unique code â†’ text mappings from columns ending in ' Text Format'\n",
    "    and append them to decoding_records (a list of dicts).\n",
    "    \"\"\"\n",
    "    text_cols = [c for c in df.columns if c.endswith(\" Text Format\")]\n",
    "\n",
    "    for text_col in text_cols:\n",
    "        code_col = text_col.replace(\" Text Format\", \"\")\n",
    "\n",
    "        if code_col not in df.columns:\n",
    "            continue\n",
    "\n",
    "        pairs = (\n",
    "            df[[code_col, text_col]]\n",
    "            .dropna()\n",
    "            .drop_duplicates()\n",
    "        )\n",
    "\n",
    "        for _, row in pairs.iterrows():\n",
    "            decoding_records.append({\n",
    "                \"variable\": code_col,\n",
    "                \"code\": row[code_col],\n",
    "                \"text\": row[text_col]\n",
    "            })\n",
    "\n",
    "    # Drop text columns after extraction\n",
    "    df = df.drop(columns=text_cols)\n",
    "\n",
    "    return df\n",
    "\n",
    "## TAKE AN INITIAL DATAFRAME (0,1,2) AND USE ITS KEEP_COLUMNS TO REMOVE UNNECESSARY INFO\n",
    "def reduce_single_df(df, keep_columns, decoding_records):\n",
    "    \"\"\"\n",
    "    Reduce a single dataframe:\n",
    "    - Keep only desired columns\n",
    "    - Extract decoding info\n",
    "    - Remove 'Text Format' columns\n",
    "    \"\"\"\n",
    "\n",
    "    # Keep only requested columns (safe intersection)\n",
    "    df = df.loc[:, df.columns.intersection(keep_columns)]\n",
    "\n",
    "    # Extract and remove text-format columns\n",
    "    df = extract_decodings(df, decoding_records)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270a77ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA CLEANING EXECUTION FUNCTION\n",
    "def clean_and_merge_crash_data(\n",
    "    dfs,\n",
    "    keep_columns_list,\n",
    "    output_dir=\"../data/clean_crash_data\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    dfs : list[pd.DataFrame]\n",
    "        List of crash dataframes\n",
    "    keep_columns_list : list[list[str]]\n",
    "        Matching list of keep-columns for each df\n",
    "    \"\"\"\n",
    "\n",
    "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    decoding_records = []\n",
    "    cleaned_dfs = []\n",
    "\n",
    "    for df, keep_cols in zip(dfs, keep_columns_list):\n",
    "        reduced = reduce_single_df(df, keep_cols, decoding_records)\n",
    "        cleaned_dfs.append(reduced)\n",
    "\n",
    "    # ---- Merge datasets ----\n",
    "    merged = pd.concat(cleaned_dfs, axis=0, ignore_index=True)\n",
    "\n",
    "    # ---- Remove duplicate columns by value ----\n",
    "    merged = merged.T.drop_duplicates().T\n",
    "\n",
    "    # ---- Save clean crash data ----\n",
    "    clean_path = Path(output_dir) / \"clean_crash_data.csv\"\n",
    "    merged.to_csv(clean_path, index=False)\n",
    "\n",
    "    # ---- Build and save decoding table ----\n",
    "    decoding_df = (\n",
    "        pd.DataFrame(decoding_records)\n",
    "        .drop_duplicates()\n",
    "        .sort_values([\"variable\", \"code\"])\n",
    "    )\n",
    "\n",
    "    decoding_path = Path(output_dir) / \"decoding_table.csv\"\n",
    "    decoding_df.to_csv(decoding_path, index=False)\n",
    "\n",
    "    return merged, decoding_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b3fc4a",
   "metadata": {},
   "source": [
    "## Gluing Files Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cadbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df, decoding_df = clean_and_merge_crash_data(\n",
    "    dfs=[df1, df2, df3],\n",
    "    keep_columns_list=[keep_columns_1, keep_columns_2, keep_columns_3]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734e1cb5",
   "metadata": {},
   "source": [
    "## Building Decoding Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70774d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Harmful Event\n",
    "# Most severe injury\n",
    "# Manner of Crash / Collision Impact\n",
    "# Location of First Harmful Evenet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eecspring",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
